{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import timm\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from typing import Optional"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DTYPE = torch.float32"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "transform1 = torchvision.transforms.Compose([\n",
    "                                                torchvision.transforms.Resize(256),\n",
    "                                                torchvision.transforms.RandomCrop(192),\n",
    "                                                torchvision.transforms.Resize(32),\n",
    "                                                torchvision.transforms.RandomCrop(32),\n",
    "                                                torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                                torchvision.transforms.ToTensor(),\n",
    "                                                #torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                                                torchvision.transforms.ConvertImageDtype(DTYPE)\n",
    "                                             ])\n",
    "\n",
    "transform2 = torchvision.transforms.Compose([\n",
    "                                                torchvision.transforms.Resize(256),\n",
    "                                                torchvision.transforms.RandomCrop(192),\n",
    "                                                torchvision.transforms.Resize(32),\n",
    "                                                torchvision.transforms.RandomCrop(32),\n",
    "                                                torchvision.transforms.ToTensor(),\n",
    "                                                #torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                                                torchvision.transforms.ConvertImageDtype(DTYPE)\n",
    "                                             ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 75\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "#lr = 0.002\n",
    "lr = 0.005\n",
    "momentum = 0.9"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.Flowers102(root='./data', split = \"train\",\n",
    "                                        download=True, transform=transform1)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.Flowers102(root='./data', split = \"val\",\n",
    "                                       download=True, transform=transform2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=8, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1425bae7c48>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torchvision.transforms.ToPILImage()(trainset[5][0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from torchvision.models.vision_transformer import Encoder\n",
    "from functools import partial\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    \"\"\"Vision Transformer as per https://arxiv.org/abs/2010.11929.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_size: int,\n",
    "        patch_size: int,\n",
    "        num_layers: int,\n",
    "        num_heads: int,\n",
    "        hidden_dim: int,\n",
    "        mlp_dim: int,\n",
    "        dropout: float = 0.0,\n",
    "        attention_dropout: float = 0.0,\n",
    "        num_classes: int = 1000,\n",
    "        representation_size: Optional[int] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if image_size % patch_size != 0:\n",
    "            print(\"Input shape indivisible by patch size!\")\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.mlp_dim = mlp_dim\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.dropout = dropout\n",
    "        self.num_classes = num_classes\n",
    "        self.representation_size = representation_size\n",
    "\n",
    "\n",
    "        self.conv_proj = nn.Conv2d(\n",
    "            in_channels=3, out_channels=hidden_dim, kernel_size=patch_size, stride=patch_size\n",
    "        )\n",
    "\n",
    "        seq_length = (image_size // patch_size) ** 2\n",
    "\n",
    "        # Add a class token\n",
    "        self.class_token = nn.Parameter(torch.zeros(1, 1, hidden_dim))\n",
    "        seq_length += 1\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            seq_length,\n",
    "            num_layers,\n",
    "            num_heads,\n",
    "            hidden_dim,\n",
    "            mlp_dim,\n",
    "            dropout,\n",
    "            attention_dropout,\n",
    "        )\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        self.heads = nn.Sequential(nn.Linear(hidden_dim, num_classes))\n",
    "\n",
    "        if isinstance(self.conv_proj, nn.Conv2d):\n",
    "            # Init the patchify stem\n",
    "            fan_in = self.conv_proj.in_channels * self.conv_proj.kernel_size[0] * self.conv_proj.kernel_size[1]\n",
    "            nn.init.trunc_normal_(self.conv_proj.weight, std=math.sqrt(1 / fan_in))\n",
    "            if self.conv_proj.bias is not None:\n",
    "                nn.init.zeros_(self.conv_proj.bias)\n",
    "        elif self.conv_proj.conv_last is not None and isinstance(self.conv_proj.conv_last, nn.Conv2d):\n",
    "            # Init the last 1x1 conv of the conv stem\n",
    "            nn.init.normal_(\n",
    "                self.conv_proj.conv_last.weight, mean=0.0, std=math.sqrt(2.0 / self.conv_proj.conv_last.out_channels)\n",
    "            )\n",
    "            if self.conv_proj.conv_last.bias is not None:\n",
    "                nn.init.zeros_(self.conv_proj.conv_last.bias)\n",
    "\n",
    "        if hasattr(self.heads, \"pre_logits\") and isinstance(self.heads.pre_logits, nn.Linear):\n",
    "            fan_in = self.heads.pre_logits.in_features\n",
    "            nn.init.trunc_normal_(self.heads.pre_logits.weight, std=math.sqrt(1 / fan_in))\n",
    "            nn.init.zeros_(self.heads.pre_logits.bias)\n",
    "\n",
    "\n",
    "    def _process_input(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        n, c, h, w = x.shape\n",
    "        p = self.patch_size\n",
    "        torch._assert(h == self.image_size, f\"Wrong image height! Expected {self.image_size} but got {h}!\")\n",
    "        torch._assert(w == self.image_size, f\"Wrong image width! Expected {self.image_size} but got {w}!\")\n",
    "        n_h = h // p\n",
    "        n_w = w // p\n",
    "\n",
    "        # (n, c, h, w) -> (n, hidden_dim, n_h, n_w)\n",
    "        x = self.conv_proj(x)\n",
    "        # (n, hidden_dim, n_h, n_w) -> (n, hidden_dim, (n_h * n_w))\n",
    "        x = x.reshape(n, self.hidden_dim, n_h * n_w)\n",
    "\n",
    "        # (n, hidden_dim, (n_h * n_w)) -> (n, (n_h * n_w), hidden_dim)\n",
    "        # The self attention layer expects inputs in the format (N, S, E)\n",
    "        # where S is the source sequence length, N is the batch size, E is the\n",
    "        # embedding dimension\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Reshape and permute the input tensor\n",
    "        x = self._process_input(x)\n",
    "        n = x.shape[0]\n",
    "\n",
    "        # Expand the class token to the full batch\n",
    "        batch_class_token = self.class_token.expand(n, -1, -1)\n",
    "        x = torch.cat([batch_class_token, x], dim=1)\n",
    "\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # Classifier \"token\" as used by standard language architectures\n",
    "        x = x[:, 0]\n",
    "\n",
    "        x = self.heads(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "    model = VisionTransformer(\n",
    "        image_size=image_size,\n",
    "        patch_size=patch_size,\n",
    "        num_layers=num_layers,\n",
    "        num_heads=num_heads,\n",
    "        hidden_dim=hidden_dim,\n",
    "        mlp_dim=mlp_dim,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    return _vision_transformer(\n",
    "        patch_size=16,\n",
    "        num_layers=12,\n",
    "        num_heads=12,\n",
    "        hidden_dim=768,\n",
    "        mlp_dim=3072,\n",
    "        weights=weights,\n",
    "        progress=progress,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "'''\n",
    "model = VisionTransformer(\n",
    "    image_size=32,\n",
    "    patch_size=8,\n",
    "    num_layers=12,\n",
    "    num_heads=12,\n",
    "    hidden_dim=768,\n",
    "    mlp_dim=3072,\n",
    "    dropout=0.2,\n",
    "    attention_dropout=0.2,\n",
    "    num_classes=102\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x14262a276c8>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(  trainset[0][0].permute(1,2,0)  )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(8, 8), stride=(8, 8))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.2, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=102, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#net = torchvision.models.vit_b_16(weights=\"IMAGENET1K_SWAG_LINEAR_V1\")\n",
    "#net.heads.head = torch.nn.Linear(net.heads.head.in_features, 10)\n",
    "\n",
    "net = model\n",
    "print(net)\n",
    "#net.heads[0] = torch.nn.Linear(net.heads[0].in_features, 10)\n",
    "\n",
    "net = net.train().to(device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def tran(epoch):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    all_counter=0\n",
    "    correct_counter=0\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        out = net(inputs)\n",
    "        out = out.detach().cpu().argmax(1)\n",
    "        t = labels.cpu()\n",
    "        for m in range(len(t)):\n",
    "            all_counter += 1\n",
    "            if t[m] == out[m]:\n",
    "                correct_counter += 1\n",
    "\n",
    "    print(correct_counter, all_counter, correct_counter / all_counter)\n",
    "    return (correct_counter / all_counter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 67.498\n",
      "21 1020 0.020588235294117647\n",
      "best:  0.020588235294117647  in NO:  0\n",
      "[2] loss: 66.261\n",
      "25 1020 0.024509803921568627\n",
      "best:  0.024509803921568627  in NO:  1\n",
      "[3] loss: 63.385\n",
      "36 1020 0.03529411764705882\n",
      "best:  0.03529411764705882  in NO:  2\n",
      "[4] loss: 59.929\n",
      "49 1020 0.04803921568627451\n",
      "best:  0.04803921568627451  in NO:  3\n",
      "[5] loss: 57.808\n",
      "61 1020 0.059803921568627454\n",
      "best:  0.059803921568627454  in NO:  4\n",
      "[6] loss: 55.918\n",
      "75 1020 0.07352941176470588\n",
      "best:  0.07352941176470588  in NO:  5\n",
      "[7] loss: 54.241\n",
      "84 1020 0.08235294117647059\n",
      "best:  0.08235294117647059  in NO:  6\n",
      "[8] loss: 53.545\n",
      "78 1020 0.07647058823529412\n",
      "[9] loss: 53.089\n",
      "103 1020 0.10098039215686275\n",
      "best:  0.10098039215686275  in NO:  8\n",
      "[10] loss: 52.529\n",
      "117 1020 0.11470588235294117\n",
      "best:  0.11470588235294117  in NO:  9\n",
      "[11] loss: 51.424\n",
      "100 1020 0.09803921568627451\n",
      "[12] loss: 50.947\n",
      "111 1020 0.10882352941176471\n",
      "[13] loss: 49.869\n",
      "117 1020 0.11470588235294117\n",
      "[14] loss: 50.047\n",
      "111 1020 0.10882352941176471\n",
      "[15] loss: 49.017\n",
      "107 1020 0.10490196078431373\n",
      "[16] loss: 48.922\n",
      "119 1020 0.11666666666666667\n",
      "best:  0.11666666666666667  in NO:  15\n",
      "[17] loss: 48.265\n",
      "134 1020 0.13137254901960785\n",
      "best:  0.13137254901960785  in NO:  16\n",
      "[18] loss: 48.136\n",
      "126 1020 0.12352941176470589\n",
      "[19] loss: 48.485\n",
      "129 1020 0.1264705882352941\n",
      "[20] loss: 47.886\n",
      "138 1020 0.13529411764705881\n",
      "best:  0.13529411764705881  in NO:  19\n",
      "[21] loss: 47.114\n",
      "135 1020 0.1323529411764706\n",
      "[22] loss: 47.062\n",
      "133 1020 0.1303921568627451\n",
      "[23] loss: 46.982\n",
      "139 1020 0.13627450980392156\n",
      "best:  0.13627450980392156  in NO:  22\n",
      "[24] loss: 46.288\n",
      "123 1020 0.12058823529411765\n",
      "[25] loss: 46.094\n",
      "146 1020 0.14313725490196078\n",
      "best:  0.14313725490196078  in NO:  24\n",
      "[26] loss: 46.188\n",
      "148 1020 0.1450980392156863\n",
      "best:  0.1450980392156863  in NO:  25\n",
      "[27] loss: 45.836\n",
      "145 1020 0.14215686274509803\n",
      "[28] loss: 45.617\n",
      "134 1020 0.13137254901960785\n",
      "[29] loss: 45.264\n",
      "157 1020 0.153921568627451\n",
      "best:  0.153921568627451  in NO:  28\n",
      "[30] loss: 45.144\n",
      "147 1020 0.14411764705882352\n",
      "[31] loss: 44.793\n",
      "146 1020 0.14313725490196078\n",
      "[32] loss: 45.234\n",
      "148 1020 0.1450980392156863\n",
      "[33] loss: 44.855\n",
      "161 1020 0.15784313725490196\n",
      "best:  0.15784313725490196  in NO:  32\n",
      "[34] loss: 44.710\n",
      "155 1020 0.15196078431372548\n",
      "[35] loss: 44.436\n",
      "158 1020 0.15490196078431373\n",
      "[36] loss: 44.424\n",
      "155 1020 0.15196078431372548\n",
      "[37] loss: 44.081\n",
      "147 1020 0.14411764705882352\n",
      "[38] loss: 44.563\n",
      "146 1020 0.14313725490196078\n",
      "[39] loss: 43.767\n",
      "162 1020 0.1588235294117647\n",
      "best:  0.1588235294117647  in NO:  38\n",
      "[40] loss: 44.554\n",
      "155 1020 0.15196078431372548\n"
     ]
    }
   ],
   "source": [
    "correctRate = 0\n",
    "for i in range(epochs):\n",
    "    tran(i)\n",
    "    r = test()\n",
    "    if(r > correctRate):\n",
    "        correctRate = r\n",
    "        print(\"best: \", r , \" in NO: \", i)\n",
    "        torch.save(net.cpu(),\"checkpoint/flow_vit.pth\")\n",
    "        net = net.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\n[1] loss: 1039.766\\n5726 10000 0.5726\\nbest:  0.5726  in NO:  0\\n[2] loss: 494.575\\n8055 10000 0.8055\\nbest:  0.8055  in NO:  1\\n[3] loss: 246.069\\n8669 10000 0.8669\\nbest:  0.8669  in NO:  2\\n[4] loss: 170.940\\n9136 10000 0.9136\\nbest:  0.9136  in NO:  3\\n[5] loss: 122.860\\n9395 10000 0.9395\\nbest:  0.9395  in NO:  4\\n[6] loss: 101.786\\n9409 10000 0.9409\\nbest:  0.9409  in NO:  5\\n[7] loss: 67.831\\n9451 10000 0.9451\\nbest:  0.9451  in NO:  6\\n[8] loss: 55.644\\n9499 10000 0.9499\\nbest:  0.9499  in NO:  7\\n[9] loss: 42.075\\n9469 10000 0.9469\\n[10] loss: 38.531\\n9587 10000 0.9587\\nbest:  0.9587  in NO:  9\\n[11] loss: 25.020\\n9565 10000 0.9565\\n[12] loss: 20.583\\n9613 10000 0.9613\\nbest:  0.9613  in NO:  11\\n[13] loss: 15.646\\n9642 10000 0.9642\\nbest:  0.9642  in NO:  12\\n[14] loss: 13.876\\n9616 10000 0.9616\\n[15] loss: 10.449\\n9660 10000 0.966\\nbest:  0.966  in NO:  14\\n[16] loss: 8.551\\n9692 10000 0.9692\\nbest:  0.9692  in NO:  15\\n[17] loss: 4.337\\n9681 10000 0.9681\\n[18] loss: 4.242\\n9740 10000 0.974\\nbest:  0.974  in NO:  17\\n[19] loss: 1.846\\n9707 10000 0.9707\\n[20] loss: 3.379\\n9695 10000 0.9695\\n\\n\\n'"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "[1] loss: 1039.766\n",
    "5726 10000 0.5726\n",
    "best:  0.5726  in NO:  0\n",
    "[2] loss: 494.575\n",
    "8055 10000 0.8055\n",
    "best:  0.8055  in NO:  1\n",
    "[3] loss: 246.069\n",
    "8669 10000 0.8669\n",
    "best:  0.8669  in NO:  2\n",
    "[4] loss: 170.940\n",
    "9136 10000 0.9136\n",
    "best:  0.9136  in NO:  3\n",
    "[5] loss: 122.860\n",
    "9395 10000 0.9395\n",
    "best:  0.9395  in NO:  4\n",
    "[6] loss: 101.786\n",
    "9409 10000 0.9409\n",
    "best:  0.9409  in NO:  5\n",
    "[7] loss: 67.831\n",
    "9451 10000 0.9451\n",
    "best:  0.9451  in NO:  6\n",
    "[8] loss: 55.644\n",
    "9499 10000 0.9499\n",
    "best:  0.9499  in NO:  7\n",
    "[9] loss: 42.075\n",
    "9469 10000 0.9469\n",
    "[10] loss: 38.531\n",
    "9587 10000 0.9587\n",
    "best:  0.9587  in NO:  9\n",
    "[11] loss: 25.020\n",
    "9565 10000 0.9565\n",
    "[12] loss: 20.583\n",
    "9613 10000 0.9613\n",
    "best:  0.9613  in NO:  11\n",
    "[13] loss: 15.646\n",
    "9642 10000 0.9642\n",
    "best:  0.9642  in NO:  12\n",
    "[14] loss: 13.876\n",
    "9616 10000 0.9616\n",
    "[15] loss: 10.449\n",
    "9660 10000 0.966\n",
    "best:  0.966  in NO:  14\n",
    "[16] loss: 8.551\n",
    "9692 10000 0.9692\n",
    "best:  0.9692  in NO:  15\n",
    "[17] loss: 4.337\n",
    "9681 10000 0.9681\n",
    "[18] loss: 4.242\n",
    "9740 10000 0.974\n",
    "best:  0.974  in NO:  17\n",
    "[19] loss: 1.846\n",
    "9707 10000 0.9707\n",
    "[20] loss: 3.379\n",
    "9695 10000 0.9695\n",
    "\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "transform1 = torchvision.transforms.Compose([\n",
    "                                                torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                                                torchvision.transforms.Resize(32),\n",
    "                                                torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                                torchvision.transforms.ToTensor(),\n",
    "                                                torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                                                torchvision.transforms.ConvertImageDtype(DTYPE)\n",
    "                                             ])\n",
    "\n",
    "transform2 = torchvision.transforms.Compose([\n",
    "                                                torchvision.transforms.Resize(32),\n",
    "                                                torchvision.transforms.ToTensor(),\n",
    "                                                torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                                                torchvision.transforms.ConvertImageDtype(DTYPE)\n",
    "                                             ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform1)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=8, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "net.heads[0] = torch.nn.Linear(net.heads[0].in_features, 10)\n",
    "\n",
    "net = net.train().to(device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.9)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def tran(epoch):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    all_counter=0\n",
    "    correct_counter=0\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        out = net(inputs)\n",
    "        out = out.detach().cpu().argmax(1)\n",
    "        t = labels.cpu()\n",
    "        for m in range(len(t)):\n",
    "            all_counter += 1\n",
    "            if t[m] == out[m]:\n",
    "                correct_counter += 1\n",
    "\n",
    "    print(correct_counter, all_counter, correct_counter / all_counter)\n",
    "    return (correct_counter / all_counter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 1298.349\n",
      "3064 10000 0.3064\n",
      "best:  0.3064  in NO:  0\n",
      "[2] loss: 1194.392\n",
      "3191 10000 0.3191\n",
      "best:  0.3191  in NO:  1\n",
      "[3] loss: 1149.447\n",
      "3682 10000 0.3682\n",
      "best:  0.3682  in NO:  2\n",
      "[4] loss: 1098.978\n",
      "3806 10000 0.3806\n",
      "best:  0.3806  in NO:  3\n",
      "[5] loss: 1073.715\n",
      "4018 10000 0.4018\n",
      "best:  0.4018  in NO:  4\n",
      "[6] loss: 1046.315\n",
      "3973 10000 0.3973\n",
      "[7] loss: 1020.158\n",
      "4385 10000 0.4385\n",
      "best:  0.4385  in NO:  6\n",
      "[8] loss: 993.714\n",
      "4282 10000 0.4282\n",
      "[9] loss: 972.843\n",
      "4397 10000 0.4397\n",
      "best:  0.4397  in NO:  8\n",
      "[10] loss: 949.513\n",
      "4528 10000 0.4528\n",
      "best:  0.4528  in NO:  9\n",
      "[11] loss: 933.218\n",
      "4798 10000 0.4798\n",
      "best:  0.4798  in NO:  10\n",
      "[12] loss: 922.124\n",
      "4834 10000 0.4834\n",
      "best:  0.4834  in NO:  11\n",
      "[13] loss: 905.796\n",
      "4898 10000 0.4898\n",
      "best:  0.4898  in NO:  12\n",
      "[14] loss: 895.214\n",
      "4727 10000 0.4727\n",
      "[15] loss: 887.258\n",
      "5093 10000 0.5093\n",
      "best:  0.5093  in NO:  14\n",
      "[16] loss: 876.171\n",
      "5070 10000 0.507\n",
      "[17] loss: 867.094\n",
      "5184 10000 0.5184\n",
      "best:  0.5184  in NO:  16\n",
      "[18] loss: 855.436\n",
      "4959 10000 0.4959\n",
      "[19] loss: 846.112\n",
      "5341 10000 0.5341\n",
      "best:  0.5341  in NO:  18\n",
      "[20] loss: 837.756\n",
      "5187 10000 0.5187\n",
      "[21] loss: 826.594\n",
      "5374 10000 0.5374\n",
      "best:  0.5374  in NO:  20\n",
      "[22] loss: 820.155\n",
      "5368 10000 0.5368\n",
      "[23] loss: 811.370\n",
      "5537 10000 0.5537\n",
      "best:  0.5537  in NO:  22\n",
      "[24] loss: 804.220\n",
      "5599 10000 0.5599\n",
      "best:  0.5599  in NO:  23\n",
      "[25] loss: 794.222\n",
      "5644 10000 0.5644\n",
      "best:  0.5644  in NO:  24\n",
      "[26] loss: 786.168\n",
      "5735 10000 0.5735\n",
      "best:  0.5735  in NO:  25\n",
      "[27] loss: 783.520\n",
      "5586 10000 0.5586\n",
      "[28] loss: 772.797\n",
      "5551 10000 0.5551\n",
      "[29] loss: 765.860\n",
      "5823 10000 0.5823\n",
      "best:  0.5823  in NO:  28\n",
      "[30] loss: 763.335\n",
      "5745 10000 0.5745\n",
      "[31] loss: 752.787\n",
      "5869 10000 0.5869\n",
      "best:  0.5869  in NO:  30\n",
      "[32] loss: 749.896\n",
      "5922 10000 0.5922\n",
      "best:  0.5922  in NO:  31\n",
      "[33] loss: 747.082\n",
      "5952 10000 0.5952\n",
      "best:  0.5952  in NO:  32\n",
      "[34] loss: 735.295\n",
      "5879 10000 0.5879\n",
      "[35] loss: 731.539\n",
      "5813 10000 0.5813\n",
      "[36] loss: 727.124\n",
      "5995 10000 0.5995\n",
      "best:  0.5995  in NO:  35\n",
      "[37] loss: 721.726\n",
      "6030 10000 0.603\n",
      "best:  0.603  in NO:  36\n",
      "[38] loss: 716.018\n",
      "6140 10000 0.614\n",
      "best:  0.614  in NO:  37\n",
      "[39] loss: 711.384\n",
      "6067 10000 0.6067\n",
      "[40] loss: 702.779\n",
      "6132 10000 0.6132\n"
     ]
    }
   ],
   "source": [
    "correctRate = 0\n",
    "for i in range(epochs):\n",
    "    tran(i)\n",
    "    r = test()\n",
    "    if(r > correctRate):\n",
    "        correctRate = r\n",
    "        print(\"best: \", r , \" in NO: \", i)\n",
    "        torch.save(net.cpu(),\"checkpoint/trans_vit.pth\")\n",
    "        net = net.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
