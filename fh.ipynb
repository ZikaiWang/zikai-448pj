{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20cc97a41d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "use_cuda = True\n",
    "DEVICE = torch.device('cuda' if (use_cuda and torch.cuda.is_available()) else 'cpu')\n",
    "torch.random.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50\n",
    "Lr = 0.01\n",
    "DTYPE = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transform1 = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.ConvertImageDtype(DTYPE),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform2 = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.ConvertImageDtype(DTYPE),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform1)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myfhNet3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myfhNet3, self).__init__()\n",
    "        self.Conv1 = torch.nn.Conv2d(3, 8, kernel_size=11, stride=1, padding=5)\n",
    "        self.Conv2 = torch.nn.Conv2d(8, 16, kernel_size=7, stride=1, padding=3)\n",
    "        self.Conv3 = torch.nn.Conv2d(16, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.Conv4 = torch.nn.Conv2d(16, 16, kernel_size=5, stride=1, padding=0)\n",
    "        self.Conv5 = torch.nn.Conv2d(16, 16, kernel_size=5, stride=1, padding=0)\n",
    "        self.Conv6 = torch.nn.Conv2d(16, 160, kernel_size=5, stride=1, padding=0)\n",
    "\n",
    "        self.maxPool = torch.nn.MaxPool2d(kernel_size = 2, stride = 2,padding=0)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(160*5*5, 160)\n",
    "        self.fc2 = torch.nn.Linear(160, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y=self.Conv1(x)\n",
    "        y=self.Conv2(y)\n",
    "        y=self.Conv3(y)\n",
    "        y=self.Conv4(y)\n",
    "        y=self.Conv5(y)\n",
    "        y=self.Conv6(y)\n",
    "\n",
    "        y=self.maxPool(y)\n",
    "        y=self.maxPool(y)\n",
    "\n",
    "        y =  torch.flatten(y,1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.fc2(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = myfhNet3()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=Lr, momentum=0.9,weight_decay=5e-4)\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 672.447\n",
      "[2] loss: 548.912\n",
      "[3] loss: 493.602\n",
      "[4] loss: 470.385\n",
      "[5] loss: 453.028\n",
      "[6] loss: 440.398\n",
      "[7] loss: 433.484\n",
      "[8] loss: 424.598\n",
      "[9] loss: 419.596\n",
      "[10] loss: 410.702\n",
      "[11] loss: 404.928\n",
      "[12] loss: 401.166\n",
      "[13] loss: 391.219\n",
      "[14] loss: 391.146\n",
      "[15] loss: 387.684\n",
      "[16] loss: 381.910\n",
      "[17] loss: 377.559\n",
      "[18] loss: 379.015\n",
      "[19] loss: 373.950\n",
      "[20] loss: 371.514\n",
      "[21] loss: 369.665\n",
      "[22] loss: 362.723\n",
      "[23] loss: 364.232\n",
      "[24] loss: 365.059\n",
      "[25] loss: 360.779\n",
      "[26] loss: 356.828\n",
      "[27] loss: 357.728\n",
      "[28] loss: 353.249\n",
      "[29] loss: 355.825\n",
      "[30] loss: 353.481\n",
      "[31] loss: 348.815\n",
      "[32] loss: 350.912\n",
      "[33] loss: 349.717\n",
      "[34] loss: 347.025\n",
      "[35] loss: 346.925\n",
      "[36] loss: 344.424\n",
      "[37] loss: 346.020\n",
      "[38] loss: 341.775\n",
      "[39] loss: 340.171\n",
      "[40] loss: 340.785\n",
      "[41] loss: 341.559\n",
      "[42] loss: 338.070\n",
      "[43] loss: 334.936\n",
      "[44] loss: 338.187\n",
      "[45] loss: 335.001\n",
      "[46] loss: 333.921\n",
      "[47] loss: 335.057\n",
      "[48] loss: 331.491\n",
      "[49] loss: 333.464\n",
      "[50] loss: 334.056\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = net.train().to(device=DEVICE)\n",
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device = DEVICE)\n",
    "        labels = labels.to(device = DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss))\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6232 10000 0.6232\n"
     ]
    }
   ],
   "source": [
    "mynet=net.eval()\n",
    "all_counter=0\n",
    "correct_counter=0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "    \n",
    "    out = mynet(inputs)\n",
    "    out = out.detach().cpu().argmax(1)\n",
    "    \n",
    "    t = labels.cpu()\n",
    "    for m in range(len(t)):\n",
    "        all_counter += 1\n",
    "        if t[m] == out[m]:\n",
    "            correct_counter += 1\n",
    "\n",
    "print(correct_counter, all_counter, correct_counter / all_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 32, 32]           2,912\n",
      "            Conv2d-2           [-1, 16, 32, 32]           6,288\n",
      "            Conv2d-3           [-1, 16, 32, 32]           6,416\n",
      "            Conv2d-4           [-1, 16, 28, 28]           6,416\n",
      "            Conv2d-5           [-1, 16, 24, 24]           6,416\n",
      "            Conv2d-6          [-1, 160, 20, 20]          64,160\n",
      "         MaxPool2d-7          [-1, 160, 10, 10]               0\n",
      "         MaxPool2d-8            [-1, 160, 5, 5]               0\n",
      "            Linear-9                  [-1, 160]         640,160\n",
      "           Linear-10                   [-1, 10]           1,610\n",
      "================================================================\n",
      "Total params: 734,378\n",
      "Trainable params: 734,378\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.12\n",
      "Params size (MB): 2.80\n",
      "Estimated Total Size (MB): 3.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1.weight torch.Size([8, 3, 11, 11])\n",
      "Conv1.bias torch.Size([8])\n",
      "Conv2.weight torch.Size([16, 8, 7, 7])\n",
      "Conv2.bias torch.Size([16])\n",
      "Conv3.weight torch.Size([16, 16, 5, 5])\n",
      "Conv3.bias torch.Size([16])\n",
      "Conv4.weight torch.Size([16, 16, 5, 5])\n",
      "Conv4.bias torch.Size([16])\n",
      "Conv5.weight torch.Size([16, 16, 5, 5])\n",
      "Conv5.bias torch.Size([16])\n",
      "Conv6.weight torch.Size([160, 16, 5, 5])\n",
      "Conv6.bias torch.Size([160])\n",
      "fc1.weight torch.Size([160, 4000])\n",
      "fc1.bias torch.Size([160])\n",
      "fc2.weight torch.Size([10, 160])\n",
      "fc2.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for key,value in net.state_dict().items():\n",
    "    print(key,value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
